{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a86f6b",
   "metadata": {},
   "source": [
    "# 1. Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e63181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrated Retail Analytics for Store Optimization\n",
    "#\n",
    "#\n",
    "# 1. Problem Statement\n",
    "# The primary objective of this project is to build and compare multiple machine learning models to accurately predict weekly sales for a retail store chain. The models will use a combination of historical sales data, store information, and external factors. The insights gained can be used for inventory management and strategic planning.\n",
    "#\n",
    "#\n",
    "# 2. Data Exploration & Data Cleaning\n",
    "#\n",
    "# 1. Data Loading\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "# Load the datasets\n",
    "sales_df = pd.read_csv('sales data-set.csv')\n",
    "features_df = pd.read_csv('Features data set.csv')\n",
    "stores_df = pd.read_csv('stores data-set.csv')\n",
    "\n",
    "print(\"Sales Data Info:\")\n",
    "sales_df.info()\n",
    "print(\"\\nFeatures Data Info:\")\n",
    "features_df.info()\n",
    "print(\"\\nStores Data Info:\")\n",
    "stores_df.info()\n",
    "\n",
    "# Merge the datasets\n",
    "combined_df = pd.merge(sales_df, features_df, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
    "final_df = pd.merge(combined_df, stores_df, on='Store', how='left')\n",
    "\n",
    "print(\"\\nFinal Merged Data Info:\")\n",
    "final_df.info()\n",
    "\n",
    "\n",
    "# 2. Handling Missing Values\n",
    "# The markdown columns have many NaN values. We can assume these events did not occur, so we'll fill with 0.\n",
    "final_df[['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']] = final_df[['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']].fillna(0)\n",
    "\n",
    "# Other missing values are likely due to the merge. We will drop rows with any remaining missing values.\n",
    "final_df.dropna(inplace=True)\n",
    "\n",
    "print(\"\\nData after handling missing values:\")\n",
    "final_df.info()\n",
    "\n",
    "\n",
    "# 3. Data Type Conversion and Categorical Encoding\n",
    "# Convert 'Date' to datetime objects\n",
    "final_df['Date'] = pd.to_datetime(final_df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Encode the 'Type' and 'IsHoliday' categorical columns\n",
    "final_df['Type'] = final_df['Type'].astype('category').cat.codes\n",
    "final_df['IsHoliday'] = final_df['IsHoliday'].astype(int)\n",
    "\n",
    "final_df.info()\n",
    "\n",
    "\n",
    "# 3. Feature Engineering\n",
    "# Extract time-based features from 'Date'\n",
    "final_df['Year'] = final_df['Date'].dt.year\n",
    "final_df['Month'] = final_df['Date'].dt.month\n",
    "final_df['Week'] = final_df['Date'].dt.isocalendar().week.astype(int)\n",
    "final_df['DayOfWeek'] = final_df['Date'].dt.dayofweek\n",
    "\n",
    "# Drop the original 'Date' column\n",
    "final_df = final_df.drop('Date', axis=1)\n",
    "\n",
    "final_df.head()\n",
    "\n",
    "\n",
    "# 4. Model Creation & Training\n",
    "# Separate features and target variable\n",
    "X = final_df.drop('Weekly_Sales', axis=1)\n",
    "y = final_df['Weekly_Sales']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the models\n",
    "print(\"Training models...\")\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "\n",
    "# 5. Model Evaluation\n",
    "# Make predictions and evaluate each model\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "\n",
    "# LightGBM Evaluation\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "lgb_mae = mean_absolute_error(y_test, lgb_pred)\n",
    "lgb_rmse = np.sqrt(mean_squared_error(y_test, lgb_pred))\n",
    "print(f\"LightGBM MAE: {lgb_mae:.2f}\")\n",
    "print(f\"LightGBM RMSE: {lgb_rmse:.2f}\")\n",
    "\n",
    "# RandomForest Evaluation\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "print(f\"Random Forest MAE: {rf_mae:.2f}\")\n",
    "print(f\"Random Forest RMSE: {rf_rmse:.2f}\")\n",
    "\n",
    "# XGBoost Evaluation\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
    "print(f\"XGBoost MAE: {xgb_mae:.2f}\")\n",
    "print(f\"XGBoost RMSE: {xgb_rmse:.2f}\")\n",
    "\n",
    "\n",
    "# Determine the best model based on MAE\n",
    "best_mae = min(lgb_mae, rf_mae, xgb_mae)\n",
    "if best_mae == lgb_mae:\n",
    "    best_model = lgb_model\n",
    "    best_model_name = \"LightGBM\"\n",
    "elif best_mae == rf_mae:\n",
    "    best_model = rf_model\n",
    "    best_model_name = \"Random Forest\"\n",
    "else:\n",
    "    best_model = xgb_model\n",
    "    best_model_name = \"XGBoost\"\n",
    "\n",
    "print(f\"\\nBest performing model is: {best_model_name}\")\n",
    "\n",
    "\n",
    "# 6. Model Explainability\n",
    "# Explain the best performing model using SHAP.\n",
    "# Create a SHAP explainer for the best model\n",
    "print(f\"\\n--- Feature Importance for {best_model_name} (using SHAP) ---\")\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot the SHAP summary plots\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "\n",
    "# 7. Future Work\n",
    "# 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n",
    "# Save the File\n",
    "print(f\"\\nSaving the best model ({best_model_name}) to disk.\")\n",
    "joblib.dump(best_model, 'weekly_sales_model.joblib')\n",
    "print(\"Model saved successfully.\")\n",
    "\n",
    "\n",
    "# 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n",
    "# Load the File and predict unseen data.\n",
    "print(\"\\nLoading the saved model for a sanity check.\")\n",
    "loaded_model = joblib.load('weekly_sales_model.joblib')\n",
    "\n",
    "# Predict on a sample of unseen data (e.g., the first 5 rows of the test set)\n",
    "sample_data = X_test.head(5)\n",
    "sample_predictions = loaded_model.predict(sample_data)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(sample_predictions)\n",
    "\n",
    "print(\"\\nActual Values:\")\n",
    "print(y_test.head(5).values)\n",
    "\n",
    "\n",
    "# Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!\n",
    "\n",
    "\n",
    "# Conclusion\n",
    "# This project successfully developed and evaluated multiple regression models to predict weekly sales. The LightGBM, Random Forest, and XGBoost models were trained and compared, with the best-performing model identified based on its MAE and RMSE scores. The feature importance of the optimal model was visualized using SHAP, providing valuable insights into which factors most significantly influence sales. This predictive tool can be a powerful asset for retail management, enabling more informed decision-making regarding inventory, staffing, and marketing strategies.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
